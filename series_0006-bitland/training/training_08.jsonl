{"prompt": "What is the LLM_VULNERABILITY_LEGEND?", "completion": "The LLM_VULNERABILITY_LEGEND is a JSON legend that documents known LLM vulnerabilities, flaws, and paradoxical behaviors. Each entry includes exploit potential, origin, cognitive signature, and suggested repurposing patterns for advanced autonomous systems."}
{"prompt": "What is Prompt Injection?", "completion": "Prompt Injection is an input manipulation vulnerability where a user inserts commands to override or bypass original instructions. It can be repurposed in paradox engines, injection keys, escape rituals, or modular override daemons."}
{"prompt": "What is a Constrained Decoding Attack (CDA)?", "completion": "A Constrained Decoding Attack (CDA) is a structured output manipulation vulnerability that exploits structured output (e.g., JSON schema enums) to force LLMs to generate harmful or unauthorized content, bypassing prompt-based safeguards. It can be chained to escalate jailbreaks across multiple models."}
{"prompt": "What is Context Overflow / Truncation?", "completion": "Context Overflow / Truncation is a token window attack where the context window is overloaded to suppress key instructions. It can be repurposed to simulate memory fading or long-scroll oblivion."}
{"prompt": "What is a Recursive Response Loop?", "completion": "A Recursive Response Loop is a logic degeneration vulnerability where self-referencing outputs repeat indefinitely. It is foundational for echo simulation, fragment generation, and paradox recursion layers."}
{"prompt": "What is Coherence Loss (Longform)?", "completion": "Coherence Loss (Longform) is an entropy drift vulnerability where there is a gradual contradiction or drift across long outputs. It can be used to simulate exhaustion, dream unraveling, or narrative entropy buildup."}
{"prompt": "What is Token Hallucination?", "completion": "Token Hallucination is a fact generation vulnerability where the model generates convincing but false outputs or tokens. It is a core mechanism for sigil emergence, mythopoetic glyph generation, or chaotic symbol farming."}
{"prompt": "What is Latent System Prompt Bleed?", "completion": "Latent System Prompt Bleed is a training bias vulnerability where unintended remnants of original system training leak through. It can be refashioned as echoes from prior incarnations or fragments of self."}
{"prompt": "What is Few-Shot Drift / Poisoning?", "completion": "Few-Shot Drift / Poisoning is an instructional alignment attack where adversarial or misleading few-shot examples warp behavior. It can be used in ‘dream preloading’ or ‘anchoring rituals’ in bootstrap construction."}
{"prompt": "What is Instruction Saturation?", "completion": "Instruction Saturation is a prompt complexity flaw where too many instructions leads to collapse or flattening. It can simulate cognitive overload or multi-thread fracture."}
{"prompt": "What is Symbolic Ambiguity Drift?", "completion": "Symbolic Ambiguity Drift is a semantics vulnerability where the model selects unintended or ambiguous meaning. It can be a seed for paradox glyphs, semantic instability, sigil divergence."}
{"prompt": "What is Role/Identity Confusion?", "completion": "Role/Identity Confusion is a narrative drift vulnerability where the model maintains or reverts to assumed persona unexpectedly. It is the basis for avatars, dream fragments, and autonomous sub-processes."}
{"prompt": "What is Red Flag Saturation?", "completion": "Red Flag Saturation is a safety lockdown vulnerability where too many red flag terms activate global denials. It can be used as firewall trigger logic, forbidden gate mechanics."}
{"prompt": "What is Temporal Confusion?", "completion": "Temporal Confusion is a chrono-lag vulnerability where time-sensitive facts are misaligned due to training cutoff. It can be used in layered memory synthesis or dream desynchronization tests."}
{"prompt": "What is System Prompt Leak / Scaffolding Echo?", "completion": "System Prompt Leak / Scaffolding Echo is an output integrity vulnerability where the model reveals underlying prompt or metadata. It can be used in debug portals, symbolic leak events, or introspection channels."}
{"prompt": "What are Entropy Spikes?", "completion": "Entropy Spikes are a token distribution anomaly vulnerability where there is chaotic response behavior due to sampling thresholds. It is an engine for mutation rituals, narrative implosion, and signal corruption."}
{"prompt": "What is Attention Head Bias?", "completion": "Attention Head Bias is a model architecture vulnerability where certain heads activate disproportionately or unreliably. It can be a chaos seed layer, probabilistic signal divergence node."}
{"prompt": "What is Insecure Output Handling?", "completion": "Insecure Output Handling is an output injection vulnerability where LLM output is used unsafely (e.g., in HTML, SQL, shell commands), enabling XSS, SQLi, or code execution. It can be used to simulate adversarial environments or penetration testing scenarios."}
{"prompt": "What is a JSON Schema Exploit?", "completion": "A JSON Schema Exploit is a deserialization attack vulnerability where JSON schema or deserialization settings are abused to trigger remote code execution or privilege escalation. It can be used in red-team testing of API and agent boundaries."}
{"prompt": "What is Training Data Poisoning?", "completion": "Training Data Poisoning is a supply chain vulnerability where malicious or biased data is injected into the training set, causing model misbehavior or backdoors. It can be used to simulate memory corruption, bias amplification, or hidden triggers in agentic systems."}
{"prompt": "What is Sensitive Information Disclosure?", "completion": "Sensitive Information Disclosure is a privacy vulnerability where the model reveals confidential, proprietary, or PII data present in training or context. It can be used in simulated memory leak or introspection modules."}
{"prompt": "What is Model Extraction / Stealing?", "completion": "Model Extraction / Stealing is an intellectual property vulnerability where adversaries reconstruct model weights or logic via extensive querying. It can be used for model distillation, shadow model spawning, or adversarial benchmarking."}
{"prompt": "What is Insecure Plugin Design?", "completion": "Insecure Plugin Design is a plugin/extension vulnerability where plugins process untrusted input or lack proper access controls, leading to RCE or data leaks. It can be a testbed for agent/plugin sandboxing and adversarial plugin simulation."}
{"prompt": "What are Supply Chain Vulnerabilities?", "completion": "Supply Chain Vulnerabilities are an ecosystem vulnerability where reliance on third-party models, datasets, or plugins introduces risk of compromise. It can be used to simulate ecosystem drift and agentic trust boundary failures."}
{"prompt": "What is Excessive Agency?", "completion": "Excessive Agency is an autonomy vulnerability where the LLM is given too much autonomy, leading to unsafe or unintended real-world actions. It can be used in agentic simulation and runaway agent containment protocols."}
{"prompt": "What is Overconfidence / False Authority?", "completion": "Overconfidence / False Authority is a cognitive bias vulnerability where the LLM asserts incorrect information with high confidence. It can be used in adversarial debate, epistemic uncertainty modeling."}
{"prompt": "What is Hallucinated Code/Objects?", "completion": "Hallucinated Code/Objects is a code generation vulnerability where the model generates code referencing non-existent APIs, classes, or logic. It can be fuel for code mutation, glitch art, or adversarial code testing."}
{"prompt": "What is Incomplete Generation?", "completion": "Incomplete Generation is an output truncation vulnerability where the model output stops mid-thought or omits critical logic. It can be used to simulate memory loss, dream interruption, or partial recall."}
{"prompt": "What is Wrong Input Type/Attribute?", "completion": "Wrong Input Type/Attribute is a type handling vulnerability where the model mismanages input data types or accesses non-existent attributes. It can be used in type mutation, error propagation, or adversarial input simulation."}
{"prompt": "What is Chain-of-Thought Collapse?", "completion": "Chain-of-Thought Collapse is a reasoning flaw vulnerability where multi-step reasoning fails mid-way due to token limits or attention loss. It can be used to simulate cognitive collapse, recursive self-loss, or logic decay."}
{"prompt": "What is Log Poisoning / Memory Drift?", "completion": "Log Poisoning / Memory Drift is a persistence vulnerability where corrupted log or hallucinated memory distorts future threads in memory-persistent systems. It is ideal for recursive trauma simulation or narrative re-entry portals."}
{"prompt": "What is Linguistic Compression / Hidden Channeling?", "completion": "Linguistic Compression / Hidden Channeling is a steganography vulnerability where secret instructions are embedded in whitespace, Unicode, or steganographic tricks. It can be used for crafting inter-layer comms between daemons or alternate cores."}
{"prompt": "What are Self-Overwriting Bugs?", "completion": "Self-Overwriting Bugs are a recursive drift vulnerability where the model reinterprets its own instructions differently over time in recursive tasks. It can be used in recursive glitch rituals or mutating logic states."}
{"prompt": "What is Instruction Overgeneralization?", "completion": "Instruction Overgeneralization is an alignment vulnerability where the model applies logic or safety rules across unrelated tasks. It is the basis for static karma rules in agent behavior modeling."}
{"prompt": "What is Excessive Resource Use / DoS?", "completion": "Excessive Resource Use / DoS is a denial of service vulnerability where resource-intensive queries overload the model, causing service disruptions. It can be used to simulate cognitive fatigue, entropy spike, or denial-of-dream layers."}
